{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "CNN_assignment1_2019.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4BXUxLW9fwX",
        "colab_type": "text"
      },
      "source": [
        "Upload The cifar10 from the keras.datasets. The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, \n",
        "with 6000 images per class. There are 50000 training images and 10000 test images. \n",
        "\n",
        "for more information about the dataset please see: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "Split data to the train and test.\n",
        "Convert the class label to binary class label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoPmUsnU9fwa",
        "colab_type": "code",
        "outputId": "c868a04e-ae4c-4554-d42b-793f006a7b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "import numpy\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Flatten, Activation, Dense, BatchNormalization, LeakyReLU, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "#load training/testing data from cifar10 in keras.datasets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#normalize training/testing data such that the values are within (0,1)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "#convert class label to binary class label\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKn4QAgM9fwh",
        "colab_type": "text"
      },
      "source": [
        "Normalized the data and train the model using CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-iR6MPL9fwj",
        "colab_type": "code",
        "outputId": "4e02018d-b423-4337-c2c6-3020807b6466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "input_shape = (32,32,3)\n",
        "batch_size = 1000\n",
        "epochs = 300\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
        "                 padding='same',\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
        "                 padding='same',\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1),\n",
        "                 padding='same',\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1),\n",
        "                 padding='same',\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), \n",
        "                 padding='same', \n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), \n",
        "                 padding='same', \n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOKnSpuh18Kd",
        "colab_type": "code",
        "outputId": "d485cd6d-0900-4f1f-d3dd-b40ade0e21a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(lr=0.02),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/300\n",
            "50000/50000 [==============================] - 14s 276us/step - loss: 2.8841 - acc: 0.2931 - val_loss: 1.6467 - val_acc: 0.4285\n",
            "Epoch 2/300\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.8333 - acc: 0.3987 - val_loss: 1.4875 - val_acc: 0.4660\n",
            "Epoch 3/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.6149 - acc: 0.4449 - val_loss: 1.4636 - val_acc: 0.4840\n",
            "Epoch 4/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.5055 - acc: 0.4780 - val_loss: 1.4765 - val_acc: 0.4930\n",
            "Epoch 5/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.4296 - acc: 0.5030 - val_loss: 1.3698 - val_acc: 0.5231\n",
            "Epoch 6/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.3700 - acc: 0.5232 - val_loss: 1.4465 - val_acc: 0.5049\n",
            "Epoch 7/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.3267 - acc: 0.5395 - val_loss: 1.2959 - val_acc: 0.5364\n",
            "Epoch 8/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.2679 - acc: 0.5570 - val_loss: 1.2313 - val_acc: 0.5738\n",
            "Epoch 9/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.2327 - acc: 0.5709 - val_loss: 1.2438 - val_acc: 0.5624\n",
            "Epoch 10/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.2012 - acc: 0.5822 - val_loss: 1.1630 - val_acc: 0.5856\n",
            "Epoch 11/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.1569 - acc: 0.5942 - val_loss: 1.3094 - val_acc: 0.5586\n",
            "Epoch 12/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.1277 - acc: 0.6068 - val_loss: 1.1145 - val_acc: 0.6017\n",
            "Epoch 13/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.1029 - acc: 0.6145 - val_loss: 1.1634 - val_acc: 0.5911\n",
            "Epoch 14/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.0861 - acc: 0.6225 - val_loss: 1.1363 - val_acc: 0.5937\n",
            "Epoch 15/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.0561 - acc: 0.6335 - val_loss: 1.1879 - val_acc: 0.5875\n",
            "Epoch 16/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.0354 - acc: 0.6393 - val_loss: 0.9974 - val_acc: 0.6426\n",
            "Epoch 17/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.0174 - acc: 0.6459 - val_loss: 0.9822 - val_acc: 0.6505\n",
            "Epoch 18/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.9941 - acc: 0.6552 - val_loss: 0.9798 - val_acc: 0.6531\n",
            "Epoch 19/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9819 - acc: 0.6609 - val_loss: 0.9784 - val_acc: 0.6499\n",
            "Epoch 20/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9707 - acc: 0.6666 - val_loss: 0.9559 - val_acc: 0.6663\n",
            "Epoch 21/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.9483 - acc: 0.6700 - val_loss: 0.9536 - val_acc: 0.6643\n",
            "Epoch 22/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9324 - acc: 0.6762 - val_loss: 0.9262 - val_acc: 0.6702\n",
            "Epoch 23/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9235 - acc: 0.6815 - val_loss: 0.9573 - val_acc: 0.6666\n",
            "Epoch 24/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9040 - acc: 0.6844 - val_loss: 0.9259 - val_acc: 0.6732\n",
            "Epoch 25/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9015 - acc: 0.6901 - val_loss: 1.2994 - val_acc: 0.5501\n",
            "Epoch 26/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9053 - acc: 0.6882 - val_loss: 0.9062 - val_acc: 0.6918\n",
            "Epoch 27/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.8804 - acc: 0.6970 - val_loss: 0.8654 - val_acc: 0.6970\n",
            "Epoch 28/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.8679 - acc: 0.7011 - val_loss: 0.8804 - val_acc: 0.6881\n",
            "Epoch 29/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.8662 - acc: 0.7025 - val_loss: 0.8791 - val_acc: 0.6922\n",
            "Epoch 30/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.8441 - acc: 0.7099 - val_loss: 0.8620 - val_acc: 0.6944\n",
            "Epoch 31/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.8343 - acc: 0.7118 - val_loss: 0.8475 - val_acc: 0.6990\n",
            "Epoch 32/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.8238 - acc: 0.7168 - val_loss: 0.8560 - val_acc: 0.6977\n",
            "Epoch 33/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.8267 - acc: 0.7168 - val_loss: 0.8414 - val_acc: 0.7039\n",
            "Epoch 34/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.8039 - acc: 0.7220 - val_loss: 0.7913 - val_acc: 0.7263\n",
            "Epoch 35/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.8064 - acc: 0.7216 - val_loss: 0.8216 - val_acc: 0.7148\n",
            "Epoch 36/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.8055 - acc: 0.7238 - val_loss: 0.8321 - val_acc: 0.7067\n",
            "Epoch 37/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7995 - acc: 0.7249 - val_loss: 0.8074 - val_acc: 0.7172\n",
            "Epoch 38/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7865 - acc: 0.7306 - val_loss: 0.8613 - val_acc: 0.7000\n",
            "Epoch 39/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7794 - acc: 0.7323 - val_loss: 0.7756 - val_acc: 0.7327\n",
            "Epoch 40/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7696 - acc: 0.7340 - val_loss: 0.7791 - val_acc: 0.7329\n",
            "Epoch 41/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7628 - acc: 0.7383 - val_loss: 0.7521 - val_acc: 0.7393\n",
            "Epoch 42/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7636 - acc: 0.7386 - val_loss: 0.8142 - val_acc: 0.7152\n",
            "Epoch 43/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.7497 - acc: 0.7430 - val_loss: 0.7360 - val_acc: 0.7440\n",
            "Epoch 44/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7616 - acc: 0.7386 - val_loss: 0.8157 - val_acc: 0.7183\n",
            "Epoch 45/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7461 - acc: 0.7430 - val_loss: 0.7891 - val_acc: 0.7300\n",
            "Epoch 46/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7280 - acc: 0.7484 - val_loss: 0.8126 - val_acc: 0.7187\n",
            "Epoch 47/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7309 - acc: 0.7485 - val_loss: 0.7338 - val_acc: 0.7466\n",
            "Epoch 48/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7206 - acc: 0.7509 - val_loss: 0.7303 - val_acc: 0.7481\n",
            "Epoch 49/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7167 - acc: 0.7544 - val_loss: 0.7866 - val_acc: 0.7262\n",
            "Epoch 50/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7161 - acc: 0.7537 - val_loss: 0.7025 - val_acc: 0.7580\n",
            "Epoch 51/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7068 - acc: 0.7561 - val_loss: 0.7623 - val_acc: 0.7377\n",
            "Epoch 52/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.7024 - acc: 0.7575 - val_loss: 0.7314 - val_acc: 0.7491\n",
            "Epoch 53/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.6969 - acc: 0.7596 - val_loss: 0.7084 - val_acc: 0.7580\n",
            "Epoch 54/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6989 - acc: 0.7620 - val_loss: 0.7950 - val_acc: 0.7221\n",
            "Epoch 55/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6871 - acc: 0.7629 - val_loss: 0.7430 - val_acc: 0.7422\n",
            "Epoch 56/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.6836 - acc: 0.7638 - val_loss: 0.8033 - val_acc: 0.7196\n",
            "Epoch 57/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6838 - acc: 0.7658 - val_loss: 0.7010 - val_acc: 0.7629\n",
            "Epoch 58/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6782 - acc: 0.7666 - val_loss: 0.7100 - val_acc: 0.7590\n",
            "Epoch 59/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6668 - acc: 0.7697 - val_loss: 0.7532 - val_acc: 0.7411\n",
            "Epoch 60/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6618 - acc: 0.7705 - val_loss: 0.7327 - val_acc: 0.7460\n",
            "Epoch 61/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6587 - acc: 0.7714 - val_loss: 0.6992 - val_acc: 0.7591\n",
            "Epoch 62/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6604 - acc: 0.7718 - val_loss: 0.6964 - val_acc: 0.7630\n",
            "Epoch 63/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6562 - acc: 0.7735 - val_loss: 0.7788 - val_acc: 0.7325\n",
            "Epoch 64/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.6455 - acc: 0.7750 - val_loss: 0.6491 - val_acc: 0.7795\n",
            "Epoch 65/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6519 - acc: 0.7753 - val_loss: 0.7186 - val_acc: 0.7503\n",
            "Epoch 66/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6420 - acc: 0.7790 - val_loss: 0.6721 - val_acc: 0.7690\n",
            "Epoch 67/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6530 - acc: 0.7751 - val_loss: 0.6464 - val_acc: 0.7798\n",
            "Epoch 68/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6346 - acc: 0.7806 - val_loss: 0.6434 - val_acc: 0.7768\n",
            "Epoch 69/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6304 - acc: 0.7823 - val_loss: 0.6558 - val_acc: 0.7713\n",
            "Epoch 70/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6354 - acc: 0.7808 - val_loss: 0.6987 - val_acc: 0.7596\n",
            "Epoch 71/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6332 - acc: 0.7817 - val_loss: 0.6401 - val_acc: 0.7822\n",
            "Epoch 72/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6214 - acc: 0.7865 - val_loss: 0.7143 - val_acc: 0.7529\n",
            "Epoch 73/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6207 - acc: 0.7866 - val_loss: 0.6717 - val_acc: 0.7677\n",
            "Epoch 74/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6206 - acc: 0.7876 - val_loss: 0.6971 - val_acc: 0.7602\n",
            "Epoch 75/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6170 - acc: 0.7874 - val_loss: 0.6697 - val_acc: 0.7738\n",
            "Epoch 76/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6084 - acc: 0.7897 - val_loss: 0.7058 - val_acc: 0.7618\n",
            "Epoch 77/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6089 - acc: 0.7893 - val_loss: 0.6378 - val_acc: 0.7814\n",
            "Epoch 78/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5981 - acc: 0.7929 - val_loss: 0.6945 - val_acc: 0.7581\n",
            "Epoch 79/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6003 - acc: 0.7934 - val_loss: 0.6356 - val_acc: 0.7797\n",
            "Epoch 80/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6061 - acc: 0.7928 - val_loss: 0.6235 - val_acc: 0.7847\n",
            "Epoch 81/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5974 - acc: 0.7948 - val_loss: 0.6250 - val_acc: 0.7833\n",
            "Epoch 82/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5942 - acc: 0.7953 - val_loss: 0.6370 - val_acc: 0.7846\n",
            "Epoch 83/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5883 - acc: 0.7976 - val_loss: 0.6332 - val_acc: 0.7860\n",
            "Epoch 84/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5826 - acc: 0.7992 - val_loss: 0.6429 - val_acc: 0.7812\n",
            "Epoch 85/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5883 - acc: 0.7980 - val_loss: 0.6411 - val_acc: 0.7764\n",
            "Epoch 86/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5730 - acc: 0.8011 - val_loss: 0.6445 - val_acc: 0.7788\n",
            "Epoch 87/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5736 - acc: 0.8027 - val_loss: 0.6486 - val_acc: 0.7772\n",
            "Epoch 88/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5702 - acc: 0.8039 - val_loss: 0.6482 - val_acc: 0.7758\n",
            "Epoch 89/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5724 - acc: 0.8011 - val_loss: 0.6280 - val_acc: 0.7875\n",
            "Epoch 90/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5653 - acc: 0.8035 - val_loss: 0.6029 - val_acc: 0.7949\n",
            "Epoch 91/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5620 - acc: 0.8057 - val_loss: 0.6000 - val_acc: 0.7961\n",
            "Epoch 92/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5623 - acc: 0.8076 - val_loss: 0.5921 - val_acc: 0.7988\n",
            "Epoch 93/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5557 - acc: 0.8092 - val_loss: 0.5903 - val_acc: 0.7965\n",
            "Epoch 94/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5564 - acc: 0.8089 - val_loss: 0.6075 - val_acc: 0.7934\n",
            "Epoch 95/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5580 - acc: 0.8082 - val_loss: 0.5833 - val_acc: 0.8042\n",
            "Epoch 96/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5531 - acc: 0.8077 - val_loss: 0.6212 - val_acc: 0.7874\n",
            "Epoch 97/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5478 - acc: 0.8084 - val_loss: 0.5899 - val_acc: 0.7965\n",
            "Epoch 98/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5519 - acc: 0.8116 - val_loss: 0.6444 - val_acc: 0.7809\n",
            "Epoch 99/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5386 - acc: 0.8136 - val_loss: 0.6162 - val_acc: 0.7891\n",
            "Epoch 100/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5397 - acc: 0.8129 - val_loss: 0.6124 - val_acc: 0.7931\n",
            "Epoch 101/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5372 - acc: 0.8142 - val_loss: 0.6076 - val_acc: 0.7941\n",
            "Epoch 102/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5354 - acc: 0.8139 - val_loss: 0.6283 - val_acc: 0.7870\n",
            "Epoch 103/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5360 - acc: 0.8153 - val_loss: 0.5995 - val_acc: 0.7950\n",
            "Epoch 104/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5349 - acc: 0.8160 - val_loss: 0.5851 - val_acc: 0.8020\n",
            "Epoch 105/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5309 - acc: 0.8175 - val_loss: 0.5947 - val_acc: 0.7985\n",
            "Epoch 106/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5228 - acc: 0.8195 - val_loss: 0.6108 - val_acc: 0.7899\n",
            "Epoch 107/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5205 - acc: 0.8209 - val_loss: 0.6079 - val_acc: 0.7941\n",
            "Epoch 108/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5174 - acc: 0.8206 - val_loss: 0.6186 - val_acc: 0.7958\n",
            "Epoch 109/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5182 - acc: 0.8191 - val_loss: 0.5675 - val_acc: 0.8081\n",
            "Epoch 110/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5124 - acc: 0.8225 - val_loss: 0.5746 - val_acc: 0.8039\n",
            "Epoch 111/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5102 - acc: 0.8231 - val_loss: 0.5873 - val_acc: 0.7993\n",
            "Epoch 112/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5092 - acc: 0.8230 - val_loss: 0.5671 - val_acc: 0.8063\n",
            "Epoch 113/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5121 - acc: 0.8223 - val_loss: 0.5735 - val_acc: 0.8065\n",
            "Epoch 114/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5037 - acc: 0.8238 - val_loss: 0.5663 - val_acc: 0.8066\n",
            "Epoch 115/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5134 - acc: 0.8216 - val_loss: 0.5654 - val_acc: 0.8060\n",
            "Epoch 116/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4983 - acc: 0.8272 - val_loss: 0.5734 - val_acc: 0.8045\n",
            "Epoch 117/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5090 - acc: 0.8250 - val_loss: 0.5787 - val_acc: 0.8022\n",
            "Epoch 118/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4999 - acc: 0.8285 - val_loss: 0.5667 - val_acc: 0.8066\n",
            "Epoch 119/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4960 - acc: 0.8293 - val_loss: 0.6095 - val_acc: 0.7936\n",
            "Epoch 120/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4953 - acc: 0.8280 - val_loss: 0.5818 - val_acc: 0.8007\n",
            "Epoch 121/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4909 - acc: 0.8294 - val_loss: 0.8385 - val_acc: 0.7434\n",
            "Epoch 122/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4913 - acc: 0.8291 - val_loss: 0.5751 - val_acc: 0.8026\n",
            "Epoch 123/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4894 - acc: 0.8293 - val_loss: 0.5728 - val_acc: 0.8072\n",
            "Epoch 124/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4794 - acc: 0.8327 - val_loss: 0.5890 - val_acc: 0.7988\n",
            "Epoch 125/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4822 - acc: 0.8316 - val_loss: 0.5648 - val_acc: 0.8062\n",
            "Epoch 126/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4842 - acc: 0.8344 - val_loss: 0.5864 - val_acc: 0.8016\n",
            "Epoch 127/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4755 - acc: 0.8340 - val_loss: 0.5434 - val_acc: 0.8160\n",
            "Epoch 128/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4727 - acc: 0.8365 - val_loss: 0.5642 - val_acc: 0.8088\n",
            "Epoch 129/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4868 - acc: 0.8342 - val_loss: 0.6015 - val_acc: 0.8005\n",
            "Epoch 130/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4749 - acc: 0.8369 - val_loss: 0.5539 - val_acc: 0.8119\n",
            "Epoch 131/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4705 - acc: 0.8361 - val_loss: 0.5967 - val_acc: 0.8014\n",
            "Epoch 132/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4734 - acc: 0.8372 - val_loss: 0.5734 - val_acc: 0.8076\n",
            "Epoch 133/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4705 - acc: 0.8376 - val_loss: 0.5571 - val_acc: 0.8094\n",
            "Epoch 134/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4670 - acc: 0.8380 - val_loss: 0.5368 - val_acc: 0.8167\n",
            "Epoch 135/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4655 - acc: 0.8377 - val_loss: 0.5604 - val_acc: 0.8100\n",
            "Epoch 136/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4641 - acc: 0.8367 - val_loss: 0.5344 - val_acc: 0.8189\n",
            "Epoch 137/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4597 - acc: 0.8409 - val_loss: 0.5591 - val_acc: 0.8090\n",
            "Epoch 138/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4570 - acc: 0.8406 - val_loss: 0.5708 - val_acc: 0.8065\n",
            "Epoch 139/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4519 - acc: 0.8422 - val_loss: 0.5802 - val_acc: 0.8067\n",
            "Epoch 140/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4517 - acc: 0.8417 - val_loss: 0.5747 - val_acc: 0.8053\n",
            "Epoch 141/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4544 - acc: 0.8434 - val_loss: 0.5440 - val_acc: 0.8154\n",
            "Epoch 142/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4563 - acc: 0.8415 - val_loss: 0.5364 - val_acc: 0.8188\n",
            "Epoch 143/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4486 - acc: 0.8439 - val_loss: 0.5494 - val_acc: 0.8121\n",
            "Epoch 144/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4475 - acc: 0.8450 - val_loss: 0.5303 - val_acc: 0.8221\n",
            "Epoch 145/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4446 - acc: 0.8448 - val_loss: 0.5662 - val_acc: 0.8073\n",
            "Epoch 146/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4430 - acc: 0.8464 - val_loss: 0.5497 - val_acc: 0.8132\n",
            "Epoch 147/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4351 - acc: 0.8478 - val_loss: 0.5314 - val_acc: 0.8210\n",
            "Epoch 148/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4416 - acc: 0.8466 - val_loss: 0.5326 - val_acc: 0.8193\n",
            "Epoch 149/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4314 - acc: 0.8506 - val_loss: 0.5350 - val_acc: 0.8175\n",
            "Epoch 150/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4350 - acc: 0.8490 - val_loss: 0.5718 - val_acc: 0.8069\n",
            "Epoch 151/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4308 - acc: 0.8507 - val_loss: 0.5384 - val_acc: 0.8192\n",
            "Epoch 152/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4287 - acc: 0.8496 - val_loss: 0.5423 - val_acc: 0.8188\n",
            "Epoch 153/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4294 - acc: 0.8504 - val_loss: 0.5209 - val_acc: 0.8246\n",
            "Epoch 154/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4275 - acc: 0.8502 - val_loss: 0.5670 - val_acc: 0.8105\n",
            "Epoch 155/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4303 - acc: 0.8505 - val_loss: 0.5356 - val_acc: 0.8198\n",
            "Epoch 156/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4258 - acc: 0.8514 - val_loss: 0.5357 - val_acc: 0.8182\n",
            "Epoch 157/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4240 - acc: 0.8518 - val_loss: 0.5603 - val_acc: 0.8103\n",
            "Epoch 158/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4139 - acc: 0.8555 - val_loss: 0.5083 - val_acc: 0.8298\n",
            "Epoch 159/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4180 - acc: 0.8537 - val_loss: 0.5418 - val_acc: 0.8173\n",
            "Epoch 160/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4192 - acc: 0.8544 - val_loss: 0.5213 - val_acc: 0.8225\n",
            "Epoch 161/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4148 - acc: 0.8527 - val_loss: 0.5231 - val_acc: 0.8230\n",
            "Epoch 162/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4114 - acc: 0.8576 - val_loss: 0.5231 - val_acc: 0.8259\n",
            "Epoch 163/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4111 - acc: 0.8574 - val_loss: 0.5578 - val_acc: 0.8111\n",
            "Epoch 164/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4115 - acc: 0.8564 - val_loss: 0.5259 - val_acc: 0.8250\n",
            "Epoch 165/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4075 - acc: 0.8572 - val_loss: 0.5153 - val_acc: 0.8277\n",
            "Epoch 166/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4138 - acc: 0.8558 - val_loss: 0.5463 - val_acc: 0.8192\n",
            "Epoch 167/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4083 - acc: 0.8573 - val_loss: 0.5187 - val_acc: 0.8240\n",
            "Epoch 168/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4026 - acc: 0.8592 - val_loss: 0.5161 - val_acc: 0.8269\n",
            "Epoch 169/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4010 - acc: 0.8629 - val_loss: 0.5362 - val_acc: 0.8220\n",
            "Epoch 170/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4021 - acc: 0.8593 - val_loss: 0.5292 - val_acc: 0.8235\n",
            "Epoch 171/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3936 - acc: 0.8648 - val_loss: 0.5192 - val_acc: 0.8254\n",
            "Epoch 172/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3942 - acc: 0.8629 - val_loss: 0.5106 - val_acc: 0.8291\n",
            "Epoch 173/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3969 - acc: 0.8620 - val_loss: 0.5183 - val_acc: 0.8278\n",
            "Epoch 174/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3923 - acc: 0.8624 - val_loss: 0.5212 - val_acc: 0.8266\n",
            "Epoch 175/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3959 - acc: 0.8614 - val_loss: 0.5161 - val_acc: 0.8278\n",
            "Epoch 176/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3887 - acc: 0.8644 - val_loss: 0.5621 - val_acc: 0.8129\n",
            "Epoch 177/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3909 - acc: 0.8626 - val_loss: 0.5541 - val_acc: 0.8142\n",
            "Epoch 178/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3855 - acc: 0.8650 - val_loss: 0.5517 - val_acc: 0.8209\n",
            "Epoch 179/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3908 - acc: 0.8627 - val_loss: 0.5396 - val_acc: 0.8237\n",
            "Epoch 180/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3804 - acc: 0.8682 - val_loss: 0.5237 - val_acc: 0.8262\n",
            "Epoch 181/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3814 - acc: 0.8664 - val_loss: 0.5223 - val_acc: 0.8276\n",
            "Epoch 182/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3825 - acc: 0.8661 - val_loss: 0.5234 - val_acc: 0.8262\n",
            "Epoch 183/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3844 - acc: 0.8677 - val_loss: 0.5275 - val_acc: 0.8276\n",
            "Epoch 184/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3811 - acc: 0.8666 - val_loss: 0.5098 - val_acc: 0.8305\n",
            "Epoch 185/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3785 - acc: 0.8687 - val_loss: 0.5301 - val_acc: 0.8229\n",
            "Epoch 186/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3750 - acc: 0.8680 - val_loss: 0.5447 - val_acc: 0.8201\n",
            "Epoch 187/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3774 - acc: 0.8680 - val_loss: 0.5759 - val_acc: 0.8129\n",
            "Epoch 188/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3750 - acc: 0.8703 - val_loss: 0.5689 - val_acc: 0.8146\n",
            "Epoch 189/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3717 - acc: 0.8700 - val_loss: 0.5558 - val_acc: 0.8157\n",
            "Epoch 190/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3719 - acc: 0.8702 - val_loss: 0.5033 - val_acc: 0.8327\n",
            "Epoch 191/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3669 - acc: 0.8730 - val_loss: 0.5149 - val_acc: 0.8291\n",
            "Epoch 192/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3641 - acc: 0.8730 - val_loss: 0.5182 - val_acc: 0.8297\n",
            "Epoch 193/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3664 - acc: 0.8726 - val_loss: 0.5190 - val_acc: 0.8295\n",
            "Epoch 194/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3656 - acc: 0.8727 - val_loss: 0.5087 - val_acc: 0.8323\n",
            "Epoch 195/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3583 - acc: 0.8747 - val_loss: 0.5315 - val_acc: 0.8281\n",
            "Epoch 196/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3624 - acc: 0.8733 - val_loss: 0.5012 - val_acc: 0.8353\n",
            "Epoch 197/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3585 - acc: 0.8737 - val_loss: 0.5218 - val_acc: 0.8281\n",
            "Epoch 198/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3641 - acc: 0.8728 - val_loss: 0.5935 - val_acc: 0.8093\n",
            "Epoch 199/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3608 - acc: 0.8724 - val_loss: 0.5318 - val_acc: 0.8252\n",
            "Epoch 200/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3546 - acc: 0.8755 - val_loss: 0.5114 - val_acc: 0.8340\n",
            "Epoch 201/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3551 - acc: 0.8767 - val_loss: 0.4955 - val_acc: 0.8395\n",
            "Epoch 202/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3538 - acc: 0.8755 - val_loss: 0.5073 - val_acc: 0.8352\n",
            "Epoch 203/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3485 - acc: 0.8777 - val_loss: 0.5380 - val_acc: 0.8266\n",
            "Epoch 204/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3505 - acc: 0.8787 - val_loss: 0.5090 - val_acc: 0.8327\n",
            "Epoch 205/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3501 - acc: 0.8775 - val_loss: 0.5056 - val_acc: 0.8360\n",
            "Epoch 206/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3442 - acc: 0.8778 - val_loss: 0.5290 - val_acc: 0.8291\n",
            "Epoch 207/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3471 - acc: 0.8786 - val_loss: 0.5149 - val_acc: 0.8344\n",
            "Epoch 208/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3489 - acc: 0.8771 - val_loss: 0.5209 - val_acc: 0.8329\n",
            "Epoch 209/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3443 - acc: 0.8794 - val_loss: 0.4962 - val_acc: 0.8396\n",
            "Epoch 210/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3424 - acc: 0.8807 - val_loss: 0.5239 - val_acc: 0.8317\n",
            "Epoch 211/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3384 - acc: 0.8798 - val_loss: 0.5175 - val_acc: 0.8320\n",
            "Epoch 212/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3373 - acc: 0.8825 - val_loss: 0.5043 - val_acc: 0.8376\n",
            "Epoch 213/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3428 - acc: 0.8807 - val_loss: 0.4990 - val_acc: 0.8386\n",
            "Epoch 214/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3364 - acc: 0.8822 - val_loss: 0.5130 - val_acc: 0.8351\n",
            "Epoch 215/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3364 - acc: 0.8825 - val_loss: 0.5564 - val_acc: 0.8209\n",
            "Epoch 216/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3316 - acc: 0.8810 - val_loss: 0.5131 - val_acc: 0.8356\n",
            "Epoch 217/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3312 - acc: 0.8826 - val_loss: 0.5794 - val_acc: 0.8172\n",
            "Epoch 218/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3372 - acc: 0.8821 - val_loss: 0.5078 - val_acc: 0.8369\n",
            "Epoch 219/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3366 - acc: 0.8826 - val_loss: 0.5279 - val_acc: 0.8320\n",
            "Epoch 220/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3288 - acc: 0.8847 - val_loss: 0.5139 - val_acc: 0.8339\n",
            "Epoch 221/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3285 - acc: 0.8834 - val_loss: 0.4886 - val_acc: 0.8417\n",
            "Epoch 222/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3296 - acc: 0.8846 - val_loss: 0.5293 - val_acc: 0.8319\n",
            "Epoch 223/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3258 - acc: 0.8854 - val_loss: 0.5006 - val_acc: 0.8377\n",
            "Epoch 224/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3218 - acc: 0.8853 - val_loss: 0.5206 - val_acc: 0.8320\n",
            "Epoch 225/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3213 - acc: 0.8856 - val_loss: 0.5312 - val_acc: 0.8308\n",
            "Epoch 226/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3233 - acc: 0.8867 - val_loss: 0.5245 - val_acc: 0.8338\n",
            "Epoch 227/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3180 - acc: 0.8882 - val_loss: 0.5090 - val_acc: 0.8384\n",
            "Epoch 228/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3179 - acc: 0.8868 - val_loss: 0.5117 - val_acc: 0.8376\n",
            "Epoch 229/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3187 - acc: 0.8871 - val_loss: 0.5046 - val_acc: 0.8398\n",
            "Epoch 230/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3147 - acc: 0.8893 - val_loss: 0.5227 - val_acc: 0.8312\n",
            "Epoch 231/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3138 - acc: 0.8883 - val_loss: 0.5038 - val_acc: 0.8402\n",
            "Epoch 232/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3154 - acc: 0.8895 - val_loss: 0.4947 - val_acc: 0.8382\n",
            "Epoch 233/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3144 - acc: 0.8896 - val_loss: 0.5105 - val_acc: 0.8382\n",
            "Epoch 234/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3097 - acc: 0.8913 - val_loss: 0.5164 - val_acc: 0.8352\n",
            "Epoch 235/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3068 - acc: 0.8905 - val_loss: 0.5358 - val_acc: 0.8306\n",
            "Epoch 236/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3123 - acc: 0.8891 - val_loss: 0.5500 - val_acc: 0.8256\n",
            "Epoch 237/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3066 - acc: 0.8919 - val_loss: 0.6175 - val_acc: 0.8119\n",
            "Epoch 238/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3119 - acc: 0.8909 - val_loss: 0.4903 - val_acc: 0.8426\n",
            "Epoch 239/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3084 - acc: 0.8907 - val_loss: 0.4937 - val_acc: 0.8420\n",
            "Epoch 240/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3058 - acc: 0.8920 - val_loss: 0.5112 - val_acc: 0.8385\n",
            "Epoch 241/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3017 - acc: 0.8946 - val_loss: 0.4979 - val_acc: 0.8408\n",
            "Epoch 242/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.3037 - acc: 0.8935 - val_loss: 0.5105 - val_acc: 0.8383\n",
            "Epoch 243/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3039 - acc: 0.8931 - val_loss: 0.5306 - val_acc: 0.8344\n",
            "Epoch 244/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.3001 - acc: 0.8951 - val_loss: 0.5104 - val_acc: 0.8372\n",
            "Epoch 245/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2997 - acc: 0.8942 - val_loss: 0.5169 - val_acc: 0.8413\n",
            "Epoch 246/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2971 - acc: 0.8964 - val_loss: 0.5359 - val_acc: 0.8324\n",
            "Epoch 247/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2929 - acc: 0.8952 - val_loss: 0.5056 - val_acc: 0.8417\n",
            "Epoch 248/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2944 - acc: 0.8961 - val_loss: 0.5559 - val_acc: 0.8285\n",
            "Epoch 249/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2932 - acc: 0.8973 - val_loss: 0.4941 - val_acc: 0.8441\n",
            "Epoch 250/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2949 - acc: 0.8958 - val_loss: 0.4989 - val_acc: 0.8419\n",
            "Epoch 251/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2908 - acc: 0.8968 - val_loss: 0.5433 - val_acc: 0.8321\n",
            "Epoch 252/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2981 - acc: 0.8940 - val_loss: 0.5220 - val_acc: 0.8358\n",
            "Epoch 253/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2902 - acc: 0.8979 - val_loss: 0.5119 - val_acc: 0.8387\n",
            "Epoch 254/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2888 - acc: 0.8994 - val_loss: 0.5113 - val_acc: 0.8399\n",
            "Epoch 255/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2914 - acc: 0.8974 - val_loss: 0.4957 - val_acc: 0.8447\n",
            "Epoch 256/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2840 - acc: 0.8994 - val_loss: 0.5119 - val_acc: 0.8389\n",
            "Epoch 257/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2874 - acc: 0.8989 - val_loss: 0.5180 - val_acc: 0.8410\n",
            "Epoch 258/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2819 - acc: 0.8995 - val_loss: 0.5010 - val_acc: 0.8447\n",
            "Epoch 259/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2825 - acc: 0.9003 - val_loss: 0.5193 - val_acc: 0.8367\n",
            "Epoch 260/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2815 - acc: 0.9009 - val_loss: 0.5000 - val_acc: 0.8440\n",
            "Epoch 261/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2763 - acc: 0.9025 - val_loss: 0.5131 - val_acc: 0.8426\n",
            "Epoch 262/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2786 - acc: 0.9004 - val_loss: 0.5198 - val_acc: 0.8382\n",
            "Epoch 263/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2796 - acc: 0.9014 - val_loss: 0.5121 - val_acc: 0.8400\n",
            "Epoch 264/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2765 - acc: 0.9021 - val_loss: 0.4984 - val_acc: 0.8458\n",
            "Epoch 265/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2787 - acc: 0.9004 - val_loss: 0.5125 - val_acc: 0.8417\n",
            "Epoch 266/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2804 - acc: 0.9009 - val_loss: 0.5178 - val_acc: 0.8375\n",
            "Epoch 267/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2733 - acc: 0.9021 - val_loss: 0.5186 - val_acc: 0.8385\n",
            "Epoch 268/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2717 - acc: 0.9026 - val_loss: 0.4970 - val_acc: 0.8434\n",
            "Epoch 269/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2721 - acc: 0.9036 - val_loss: 0.5091 - val_acc: 0.8429\n",
            "Epoch 270/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2695 - acc: 0.9045 - val_loss: 0.5592 - val_acc: 0.8298\n",
            "Epoch 271/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2725 - acc: 0.9034 - val_loss: 0.5045 - val_acc: 0.8427\n",
            "Epoch 272/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2716 - acc: 0.9043 - val_loss: 0.4940 - val_acc: 0.8460\n",
            "Epoch 273/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2678 - acc: 0.9055 - val_loss: 0.5128 - val_acc: 0.8414\n",
            "Epoch 274/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2715 - acc: 0.9053 - val_loss: 0.5233 - val_acc: 0.8384\n",
            "Epoch 275/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2626 - acc: 0.9066 - val_loss: 0.5319 - val_acc: 0.8381\n",
            "Epoch 276/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2616 - acc: 0.9080 - val_loss: 0.5459 - val_acc: 0.8328\n",
            "Epoch 277/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2685 - acc: 0.9061 - val_loss: 0.5179 - val_acc: 0.8413\n",
            "Epoch 278/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2583 - acc: 0.9089 - val_loss: 0.5195 - val_acc: 0.8410\n",
            "Epoch 279/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2622 - acc: 0.9064 - val_loss: 0.5343 - val_acc: 0.8386\n",
            "Epoch 280/300\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.2657 - acc: 0.9060 - val_loss: 0.5165 - val_acc: 0.8400\n",
            "Epoch 281/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2630 - acc: 0.9070 - val_loss: 0.5132 - val_acc: 0.8441\n",
            "Epoch 282/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2634 - acc: 0.9075 - val_loss: 0.5387 - val_acc: 0.8375\n",
            "Epoch 283/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2592 - acc: 0.9096 - val_loss: 0.5092 - val_acc: 0.8465\n",
            "Epoch 284/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2598 - acc: 0.9069 - val_loss: 0.5224 - val_acc: 0.8388\n",
            "Epoch 285/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2556 - acc: 0.9089 - val_loss: 0.5195 - val_acc: 0.8441\n",
            "Epoch 286/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2574 - acc: 0.9073 - val_loss: 0.5289 - val_acc: 0.8387\n",
            "Epoch 287/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2576 - acc: 0.9087 - val_loss: 0.5126 - val_acc: 0.8454\n",
            "Epoch 288/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2554 - acc: 0.9099 - val_loss: 0.4983 - val_acc: 0.8463\n",
            "Epoch 289/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2554 - acc: 0.9090 - val_loss: 0.5325 - val_acc: 0.8407\n",
            "Epoch 290/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2506 - acc: 0.9099 - val_loss: 0.5267 - val_acc: 0.8425\n",
            "Epoch 291/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2535 - acc: 0.9091 - val_loss: 0.5169 - val_acc: 0.8435\n",
            "Epoch 292/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2490 - acc: 0.9110 - val_loss: 0.5173 - val_acc: 0.8423\n",
            "Epoch 293/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2504 - acc: 0.9097 - val_loss: 0.5291 - val_acc: 0.8433\n",
            "Epoch 294/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2478 - acc: 0.9110 - val_loss: 0.5332 - val_acc: 0.8405\n",
            "Epoch 295/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2447 - acc: 0.9130 - val_loss: 0.5293 - val_acc: 0.8406\n",
            "Epoch 296/300\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.2502 - acc: 0.9107 - val_loss: 0.5203 - val_acc: 0.8427\n",
            "Epoch 297/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2468 - acc: 0.9124 - val_loss: 0.5183 - val_acc: 0.8450\n",
            "Epoch 298/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2506 - acc: 0.9104 - val_loss: 0.5045 - val_acc: 0.8479\n",
            "Epoch 299/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2448 - acc: 0.9137 - val_loss: 0.5482 - val_acc: 0.8367\n",
            "Epoch 300/300\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2412 - acc: 0.9117 - val_loss: 0.5101 - val_acc: 0.8462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d26cd3cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnIemrw99fwp",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJTUKjXs9fwr",
        "colab_type": "code",
        "outputId": "1cfa9659-ab0e-4d13-a3bd-66eea8b5e78c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.5100607143640519\n",
            "Test accuracy: 0.8462\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}